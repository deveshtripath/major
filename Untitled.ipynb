{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"linkdin.html\",'r',encoding='utf-8') as f:\n",
    "    page = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Feed Updates\\n  '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('h1')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Feed post number 1            Pradip Nichite likes this         Status is offline      Dhaval Patel             â€¢ 2nd                      Helping People Become Data Professionals ðŸ‘‰ codebasics.io | Youtuber - 700K+ Subscribers | Ex. Bloomberg, NVIDIA        2d â€¢  2 days agoFollow  During an interview, I allow a candidate to use the internet ðŸŒŽTo get help on code syntax, etc. I pay attention to what exactly they search for. It helps me understand how they navigate through an abundance of information to find the necessary ingredients for accomplishing a given task. After all, that's exactly what they will be doing after they are hired!In short: Search Skill > Memorization Skill#interview â€¦see more8,833            172 comments                      143 reposts                     Like             CommentRepostSend in a private messageSend\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('div',class_='relative').get_text().replace('\\n','').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dhaval Patel'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('span', class_='update-components-actor__name').get_text().replace('\\n','').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Helping People Become Data Professionals ðŸ‘‰ codebasics.io | Youtuber - 700K+ Subscribers | Ex. Bloomberg, NVIDIA'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('span', class_='update-components-actor__description').get_text().replace('\\n','').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"During an interview, I allow a candidate to use the internet ðŸŒŽTo get help on code syntax, etc. I pay attention to what exactly they search for. It helps me understand how they navigate through an abundance of information to find the necessary ingredients for accomplishing a given task. After all, that's exactly what they will be doing after they are hired!In short: Search Skill > Memorization Skill#interview\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('div', class_='update-components-text').get_text().replace('\\n','').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# company = soup.find('ul',class_='social-details-social-counts')\n",
    "# for i in company:\n",
    "#     print(i.find('li',class_='social-details-social-counts__item social-details-social-counts__reactions')[0].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8,833            172 comments                      143 reposts'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('ul', class_='social-details-social-counts').get_text().replace('\\n','').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'172 comments'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('li', class_='social-details-social-counts__item--with-social-proof').get_text().replace('\\n','').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8,833'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('li', class_='social-details-social-counts__item').get_text().replace('\\n','').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'143 reposts'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('li', class_='social-details-social-counts__item social-details-social-counts__item--with-social-proof').get_text().replace('\\n','').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1162"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup.find_all('div',class_='relative'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"linkdin.html\",'r',encoding='utf-8') as f:\n",
    "    page = f.read()\n",
    "soup=BeautifulSoup(page,'lxml')\n",
    "\n",
    "set_file = soup.select(\"div.relative div.feed-shared-update-v2--minimal-padding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=pd.DataFrame()\n",
    "user = []\n",
    "about = []\n",
    "post = []\n",
    "comment = []\n",
    "like = []\n",
    "reports = []\n",
    "cnt = 1\n",
    "# while cnt <= 10:\n",
    "#     user.append(soup.find('span', class_='update-components-actor__name').get_text().replace('\\n','').strip())\n",
    "#     about.append(soup.find('span', class_='update-components-actor__description').get_text().replace('\\n','').strip())\n",
    "#     post.append(soup.find('div', class_='update-components-text').get_text().replace('\\n','').strip())\n",
    "#     comment.append(soup.find('li', class_='social-details-social-counts__item--with-social-proof').get_text().replace('\\n','').strip())\n",
    "#     like.append(soup.find('li', class_='social-details-social-counts__item').get_text().replace('\\n','').strip())\n",
    "#     reports.append(soup.find('li', class_='social-details-social-counts__item social-details-social-counts__item--with-social-proof').get_text().replace('\\n','').strip())\n",
    "#     cnt = cnt +1\n",
    "#     print(cnt)\n",
    "\n",
    "\n",
    "# try:\n",
    "#     formats_on_page = set_file.select(\"div.update-components-actor a.app-aware-link div.update-components-actor__meta span.update-components-actor__name\")\n",
    "#     for product_format in formats_on_page:\n",
    "#         if product_format == \"\":\n",
    "#             user.append(np.nan)\n",
    "#         else:    \n",
    "#             user.append(product_format.get_text().replace('\\n','').strip())\n",
    "# except:\n",
    "#     user.append(np.nan)\n",
    "    \n",
    "# try:\n",
    "#     formats_on_page = soup.select(\"div.relative div.feed-shared-update-v2--minimal-padding div.update-components-actor a.app-aware-link div.update-components-actor__meta span.update-components-actor__description\")\n",
    "#     for product_format in formats_on_page:\n",
    "#         if product_format == \"\":\n",
    "#             about.append(np.nan)\n",
    "#         else:    \n",
    "#             about.append(product_format.get_text().replace('\\n','').strip())\n",
    "# except:\n",
    "#     about.append(np.nan)    \n",
    "\n",
    "try:\n",
    "    formats_on_page = soup.select(\"div.relative div.feed-shared-update-v2--minimal-padding div.feed-shared-update-v2__description-wrapper div.update-components-text span.break-words\")\n",
    "    for product_format in formats_on_page:\n",
    "        if product_format == \"\":\n",
    "            post.append(np.nan)\n",
    "        else:    \n",
    "            post.append(product_format.get_text().replace('\\n','').strip())\n",
    "except:\n",
    "    post.append(np.nan)    \n",
    "\n",
    "# try:\n",
    "#     formats_on_page = soup.select(\"div.relative div.feed-shared-update-v2--minimal-padding div.social-details-social-activity ul.social-details-social-counts li.social-details-social-counts__item--with-social-proof\")\n",
    "#     for product_format in formats_on_page:\n",
    "#         comment.append(product_format.get_text().replace('\\n','').strip())\n",
    "# except:\n",
    "#     comment.append(np.nan)    \n",
    "\n",
    "    \n",
    "# try:\n",
    "#     formats_on_page = soup.select(\"div.relative div.feed-shared-update-v2--minimal-padding div.social-details-social-activity ul.social-details-social-counts li.social-details-social-counts__item\")\n",
    "#     for product_format in formats_on_page:\n",
    "#         like.append(product_format.get_text().replace('\\n','').strip())\n",
    "# except:\n",
    "#     like.append(np.nan)    \n",
    "\n",
    "    \n",
    "# try:\n",
    "#     formats_on_page = soup.select(\"div.relative div.feed-shared-update-v2--minimal-padding div.social-details-social-activity ul.social-details-social-counts li.social-details-social-counts__item social-details-social-counts__item--with-social-proof\")\n",
    "#     for product_format in formats_on_page:\n",
    "#         reports.append(product_format.get_text().replace('\\n','').strip())\n",
    "# except:\n",
    "#     reports.append(np.nan)    \n",
    "\n",
    "\n",
    "# df=pd.DataFrame({\n",
    "# #     'user':user,\n",
    "# #        'About':about,\n",
    "#        'Post':post,\n",
    "# #        'Comment':comment,\n",
    "# #        'Like':like,\n",
    "# #        'Report':reports\n",
    "# })\n",
    "# final=final.append(df,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "165\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(user))\n",
    "print(len(about))\n",
    "print(len(post))\n",
    "print(len(comment))\n",
    "print(len(like))\n",
    "print(len(reports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     formats_on_page = soup.select(\"li.social-details-social-counts__item social-details-social-counts__item--with-social-proof\")\n",
    "#     for product_format in formats_on_page:\n",
    "#         user.append(product_format.get_text().replace('\\n','').strip())\n",
    "# except:\n",
    "#     plot.append(np.nan)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_file = soup.select(\"div.feed-shared-update-v2--minimal-padding\")\n",
    "# print(len(set_file))\n",
    "# # set_file[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user = []\n",
    "# about = []\n",
    "# post = []\n",
    "# comment = []\n",
    "# like = []\n",
    "# reports = []\n",
    "# cnt = 0\n",
    "# for i in set_file:\n",
    "#     print(i.select(\"div.feed-shared-update-v2__description-wrapper div.update-components-text span.break-words\"))\n",
    "#     try:\n",
    "#         formats_on_page = i.select(\"div.update-components-actor__meta span.update-components-actor__name\")\n",
    "#         for product_format in formats_on_page:\n",
    "#             if product_format == \"\":\n",
    "#                 user.append(np.nan)\n",
    "#             else:    \n",
    "#                 user.append(product_format.get_text().replace('\\n','').strip())\n",
    "#     except:\n",
    "#         user.append(np.nan)\n",
    "\n",
    "#     try:\n",
    "#         formats_on_page = i.select(\"div.update-components-actor__meta span.update-components-actor__description\")\n",
    "#         for product_format in formats_on_page:\n",
    "#             if product_format == \"\":\n",
    "#                 about.append(np.nan)\n",
    "#             else:    \n",
    "#                 about.append(product_format.get_text().replace('\\n','').strip())\n",
    "#     except:\n",
    "#         about.append(np.nan)    \n",
    "\n",
    "# #     try:\n",
    "# #         formats_on_page = i.select(\"div.update-components-text span.break-words\")\n",
    "# #         for product_format in formats_on_page:\n",
    "# #             if product_format == \"\" or product_format == np.nan:\n",
    "# #                 post.append(np.nan)\n",
    "# #             else:    \n",
    "# #                 post.append(product_format.get_text().replace('\\n','').strip())\n",
    "# #     except:\n",
    "# #         post.append(np.nan)    \n",
    "\n",
    "# #     try:\n",
    "# #         formats_on_page = i.select(\"div.social-details-social-activity ul.social-details-social-counts li.social-details-social-counts__item--with-social-proof\")\n",
    "# #         for product_format in formats_on_page:\n",
    "# #             comment.append(product_format.get_text().replace('\\n','').strip())\n",
    "# #     except:\n",
    "# #         comment.append(np.nan)    \n",
    "\n",
    "\n",
    "# #     try:\n",
    "# #         formats_on_page = i.select(\"div.social-details-social-activity ul.social-details-social-counts li.social-details-social-counts__item\")\n",
    "# #         for product_format in formats_on_page:\n",
    "# #             like.append(product_format.get_text().replace('\\n','').strip())\n",
    "# #     except:\n",
    "# #         like.append(np.nan)    \n",
    "\n",
    "\n",
    "# #     try:\n",
    "# #         formats_on_page = i.select(\"div.social-details-social-activity ul.social-details-social-counts li.social-details-social-counts__item social-details-social-counts__item--with-social-proof\")\n",
    "# #         for product_format in formats_on_page:\n",
    "# #             reports.append(product_format.get_text().replace('\\n','').strip())\n",
    "# #     except:\n",
    "# #         reports.append(np.nan)    \n",
    "\n",
    "\n",
    "#     df=pd.DataFrame({\n",
    "#         'user':user,\n",
    "#            'About':about,\n",
    "#            'Post':post,\n",
    "# #            'Comment':comment,\n",
    "# #            'Like':like,\n",
    "# #            'Report':reports\n",
    "#     })\n",
    "#     final=final.append(df,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_file = soup.select(\"div.relative div.feed-shared-update-v2--minimal-padding div.update-components-actor\")\n",
    "# print(len(set_file))\n",
    "# set_file[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formats_on_page = soup.select(\"div.relative div.feed-shared-update-v2--minimal-padding div.update-components-actor a.app-aware-link div.update-components-actor__meta span.update-components-actor__name\")\n",
    "# formats_on_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"linkdin_new.html\",'r',encoding='utf-8') as f:\n",
    "    page = f.read()\n",
    "soup=BeautifulSoup(page,'lxml')\n",
    "\n",
    "set_file = soup.select(\"div.relative div.feed-shared-update-v2--minimal-padding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    formats_on_page = soup.select(\"div.relative div.feed-shared-update-v2--minimal-padding div.feed-shared-update-v2__description-wrapper div.update-components-text span.break-words\")\n",
    "    for product_format in formats_on_page:\n",
    "        if product_format == \"\":\n",
    "            post.append(np.nan)\n",
    "        else:    \n",
    "            post.append(product_format.get_text().replace('\\n','').strip())\n",
    "except:\n",
    "    post.append(np.nan) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-40-a70cdf0ca598>:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  final=final.append(df,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame({\n",
    "       'Post':post,\n",
    "})\n",
    "final=final.append(df,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>During an interview, I allow a candidate to us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delivered by expert PMs from Toothsi, IBM, Pay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ðŸŽ§ðŸŽ‰The DJ Night at Epoque@Prastuti 2023 was a n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The value of 1 Crore, after: - 10 years from n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Friday sharing posts FB-https://lnkd.in/dgtM8hz7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>Great rejoicings and festivities followed the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>Hello everyone!I'm pleased to share that I've ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>So Hera Pheri 3 is finally happening! Look for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>Vision isnâ€™t always about seeing what exists, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>With MagiScan, you can scan objects of various...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>339 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Post\n",
       "0    During an interview, I allow a candidate to us...\n",
       "1    Delivered by expert PMs from Toothsi, IBM, Pay...\n",
       "2    ðŸŽ§ðŸŽ‰The DJ Night at Epoque@Prastuti 2023 was a n...\n",
       "3    The value of 1 Crore, after: - 10 years from n...\n",
       "4     Friday sharing posts FB-https://lnkd.in/dgtM8hz7\n",
       "..                                                 ...\n",
       "334  Great rejoicings and festivities followed the ...\n",
       "335  Hello everyone!I'm pleased to share that I've ...\n",
       "336  So Hera Pheri 3 is finally happening! Look for...\n",
       "337  Vision isnâ€™t always about seeing what exists, ...\n",
       "338  With MagiScan, you can scan objects of various...\n",
       "\n",
       "[339 rows x 1 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
